{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare Data and Synthetics for Moment Tensor Inversion\n",
    "\n",
    "Now, we are about to do the inversion. But before that, we need to prepare the data and the synthetics that are required for moment tensor inversion.\n",
    "we need to create synthetic Green's functions that is required for the inversion. In this notebook we will do:\n",
    "- **Filter and cut the seismograms**;\n",
    "- **Calculate and filter synthetic Green's functions**;\n",
    "- **Prepare input file for moment tensor inversion**. \n",
    "\n",
    "We will use wavenumber integration (FK) method for creating the synthetics. There are many softwares, and here we use the software package ***Computer Programs in Seismology ([CPS](http://www.eas.slu.edu/eqc/eqccps.html))*** by R.B Herrmann.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import third-party libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from obspy.core import read, UTCDateTime, Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Filter and cut the seismograms\n",
    "\n",
    "# Prepare the folders/directories\n",
    "evid = \"41423391\" #!!! event of interest\n",
    "event_dir = evid\n",
    "infile = \"%s/datetime.csv\"%event_dir # we need the event origin time\n",
    "station_file = \"%s/station.csv\"%event_dir\n",
    "\n",
    "sacdir = \"%s/sac\"%event_dir # location of pre-processed data\n",
    "outdir = \"%s\"%event_dir     # location of filtered/cut/down-sampled data for inversion\n",
    "    \n",
    "# Check if data directory exist\n",
    "P = Path(sacdir)\n",
    "if P.exists():\n",
    "    # Read event info and station info into Pandas table\n",
    "    df = pd.read_csv(infile,parse_dates=True)\n",
    "    station_df = pd.read_csv(\"%s\"%(station_file),parse_dates=True,dtype={\"location\":str},na_filter=False)\n",
    "    \n",
    "    origin_time = UTCDateTime(df[\"origin\"][0])\n",
    "    st = Stream()\n",
    "    for _,row in station_df.iterrows():\n",
    "        st += read(\"%s/%s.%s.%s.%s[%s]\"%(\n",
    "            sacdir,row.network,row.station,row.location,row.channel,row.component),format=\"SAC\")\n",
    "else:\n",
    "    print(\"Directory %s does not exist. %s does not have instrument corrected data.\"%(sacdir,evid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for processing data\n",
    "#   You may need to change them for different events. \n",
    "#   Synthetic Green's functions must have the same filter, \n",
    "#   reduction velocity and sampling interval as the data.\n",
    "\n",
    "# Filter parameters\n",
    "freqmin = 0.02\n",
    "freqmax = 0.05\n",
    "corners = 3\n",
    "\n",
    "# Desired sampling interval\n",
    "dt = 1.0\n",
    "\n",
    "# Reduction velocity in km/sec, 0 sets the reference time to origin time\n",
    "vred = 0\n",
    "\n",
    "# time before and after reference time, data will be cut before and after the reference time\n",
    "time_before = 30\n",
    "time_after = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vred:\n",
    "    p = 1/vred\n",
    "else:\n",
    "    p = 0\n",
    "\n",
    "# filter and taper\n",
    "st.filter(\"bandpass\",freqmin=freqmin,freqmax=freqmax,corners=corners,zerophase=True)\n",
    "st.taper(max_percentage=0.05)\n",
    "\n",
    "# Trim and resample the data\n",
    "for tr in st:\n",
    "    ## resample the seismograms\n",
    "    tr.decimate(factor=int(tr.stats.sampling_rate*dt), strict_length=False, no_filter=True)\n",
    "    tr.resample(1/dt, strict_length=False, no_filter=True)\n",
    "    tr.stats.sac.t1 = origin_time + p*(tr.stats.sac.dist) # set reference time\n",
    "    \n",
    "    ## trim the seismograms\n",
    "    tr.trim(tr.stats.sac.t1-time_before,tr.stats.sac.t1+time_after,pad=True,fill_value=0)\n",
    "    tr.data = 100*tr.data # m/s to cm/s\n",
    "    tr.stats.sac.b = -1*(origin_time - tr.stats.starttime)\n",
    "    tr.stats.sac.o = 0\n",
    "    \n",
    "    ## Save final trace using tdmtpy file name format\n",
    "    sacout = \"%s/%s.%s.dat\"%(outdir,tr.id[:-4],tr.id[-1])\n",
    "    tr.write(sacout,format=\"SAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output synthetics 41423391/gil7/BK.MTOS.00.10.0000....\n",
      "Output synthetics 41423391/gil7/BK.FARB.00.10.0000....\n",
      "Output synthetics 41423391/gil7/BK.MNRC.00.10.0000....\n",
      "Output synthetics 41423391/gil7/BK.WELL.00.10.0000....\n",
      "Output synthetics 41423391/gil7/BK.FORD.00.10.0000....\n",
      "Output synthetics 41423391/gil7/BK.SAO.00.10.0000....\n",
      "Output synthetics 41423391/gil7/BK.MTOS.00.20.0000....\n",
      "Output synthetics 41423391/gil7/BK.FARB.00.20.0000....\n",
      "Output synthetics 41423391/gil7/BK.MNRC.00.20.0000....\n",
      "Output synthetics 41423391/gil7/BK.WELL.00.20.0000....\n",
      "Output synthetics 41423391/gil7/BK.FORD.00.20.0000....\n",
      "Output synthetics 41423391/gil7/BK.SAO.00.20.0000....\n",
      "Output synthetics 41423391/gil7/BK.MTOS.00.30.0000....\n",
      "Output synthetics 41423391/gil7/BK.FARB.00.30.0000....\n",
      "Output synthetics 41423391/gil7/BK.MNRC.00.30.0000....\n",
      "Output synthetics 41423391/gil7/BK.WELL.00.30.0000....\n",
      "Output synthetics 41423391/gil7/BK.FORD.00.30.0000....\n",
      "Output synthetics 41423391/gil7/BK.SAO.00.30.0000....\n",
      "Output synthetics 41423391/gil7/BK.MTOS.00.40.0000....\n",
      "Output synthetics 41423391/gil7/BK.FARB.00.40.0000....\n",
      "Output synthetics 41423391/gil7/BK.MNRC.00.40.0000....\n",
      "Output synthetics 41423391/gil7/BK.WELL.00.40.0000....\n",
      "Output synthetics 41423391/gil7/BK.FORD.00.40.0000....\n",
      "Output synthetics 41423391/gil7/BK.SAO.00.40.0000....\n",
      "Output synthetics 41423391/gil7/BK.MTOS.00.50.0000....\n",
      "Output synthetics 41423391/gil7/BK.FARB.00.50.0000....\n",
      "Output synthetics 41423391/gil7/BK.MNRC.00.50.0000....\n",
      "Output synthetics 41423391/gil7/BK.WELL.00.50.0000....\n",
      "Output synthetics 41423391/gil7/BK.FORD.00.50.0000....\n",
      "Output synthetics 41423391/gil7/BK.SAO.00.50.0000....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Calculate the synthetic Green's functions\n",
    "#   The calculation requires two input files, a velocity model file and a distance file. \n",
    "\n",
    "model  = \"gil7\" # that means the model file is \"gil7.d\"\n",
    "depths = sorted([10,20,30,40,50]) # compute GF at 10, 20, ..., km\n",
    "npts   = int(256) # number of points in the time series, must be a power of 2\n",
    "t0     = int(0)   # used to define the first sample point, t0 + distance_in_km/vred\n",
    "\n",
    "# Location to store synthetic Green's functions\n",
    "green_dir = \"%s/%s\"%(event_dir,model)\n",
    "Path(green_dir).mkdir(parents=True,exist_ok=True)\n",
    "    \n",
    "for depth in depths:\n",
    "    # Create distance file\n",
    "    dfile = (\"{dist:.0f} {dt:.2f} {npts:d} {t0:d} {vred:.1f}\\n\")\n",
    "    dfile_out = \"%s/dfile\"%event_dir\n",
    "    with open(dfile_out,\"w\") as f:\n",
    "        for _,row in station_df.iterrows():\n",
    "            f.write(dfile.format(dist=row.distance,dt=dt,npts=npts,t0=t0,vred=vred))\n",
    "\n",
    "    # Generate the synthetics\n",
    "    os.system(\"hprep96 -M %s.d -d %s -HS %.4f -HR 0 -EQEX\"%(model,dfile_out,depth))\n",
    "    os.system(\"hspec96\")\n",
    "    os.system(\"hpulse96 -D -i > file96\")\n",
    "    os.system(\"f96tosac -B file96\")\n",
    "\n",
    "    # Filter and save the synthetic Green's functions\n",
    "    greens = (\"ZDD\",\"RDD\",\"ZDS\",\"RDS\",\"TDS\",\"ZSS\",\"RSS\",\"TSS\",\"ZEX\",\"REX\")\n",
    "\n",
    "    for index,row in station_df.iterrows():      \n",
    "        for j,grn in enumerate(greens):\n",
    "            sacin = \"B%03d%02d%s.sac\"%(index+1,j+1,grn)\n",
    "            sacout = \"%s/%s.%s.%s.%.4f\"%(green_dir,row.network,row.station,row.location,depth)\n",
    "            tmp = read(sacin,format=\"SAC\")\n",
    "            tmp.filter('bandpass',freqmin=freqmin,freqmax=freqmax,corners=corners,zerophase=True)\n",
    "            filename = \"%s.%s\"%(sacout,grn) \n",
    "            tmp.write(filename,format=\"SAC\") # overwrite\n",
    "        print(\"Output synthetics %s...\" % (filename[:-3]) )\n",
    "\n",
    "# Uncomment to remove unfiltered synthetic SAC files\n",
    "os.system(\"rm B*.sac\") # remove the unfiltered SAC files\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Create input file for MTtime\n",
    "#   Now that we have prepared the data and synthetics for inversion.\n",
    "#   we can create the input file for tdmtpy.\n",
    "#   I will go over the input file format in the next notebook.\n",
    "\n",
    "\n",
    "# Create headers\n",
    "headers = dict(datetime=df[\"origin\"][0],\n",
    "               longitude=df[\"lon\"][0],\n",
    "               latitude=df[\"lat\"][0],\n",
    "               depth=\",\".join([ \"%.4f\"%d for d in depths]),\n",
    "               path_to_data=event_dir,\n",
    "               path_to_green=green_dir,\n",
    "               green=\"herrmann\",\n",
    "               components=\"ZRT\",\n",
    "               degree=5,\n",
    "               weight=\"distance\",\n",
    "               plot=0,\n",
    "               correlate=0,\n",
    "              )\n",
    "\n",
    "# Add station table\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "frame = {\"station\": station_df[[\"network\",\"station\",\"location\"]].apply(lambda x: \".\".join(x),axis=1)}\n",
    "df_out = pd.DataFrame(frame)\n",
    "df_out[[\"distance\",\"azimuth\"]] = station_df[[\"distance\",\"azimuth\"]]\n",
    "df_out[\"ts\"] = int(30)\n",
    "df_out[\"npts\"] = int(150)\n",
    "df_out[\"dt\"] = dt\n",
    "df_out[\"used\"] = 1\n",
    "df_out[[\"longitude\",\"latitude\"]] = station_df[[\"longitude\",\"latitude\"]]\n",
    "#print(df_out.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file **mtinv.in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write\n",
    "with open(\"mtinv.in\",\"w\") as f:\n",
    "    for key, value in headers.items():\n",
    "        f.write(\"{0:<15}{1}\\n\".format(key,value))\n",
    "    f.write(df_out.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can start the next tutorial and take a look at the moment tensor inversion package `mttime`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
